{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data gathering imports\n",
    "import config\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import tweepy\n",
    "import json\n",
    "\n",
    "# standard data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import WeRateDogs twitter archive (provided by Udacity)\n",
    "archive = pd.read_csv('twitter-archive-enhanced.csv')\n",
    "\n",
    "# download Udacity's tweet image predictions\n",
    "preds = requests.get('https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv',\n",
    "                 auth=('user', 'pass'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tweet IDs to a variable\n",
    "tweet_id = archive['tweet_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@dapplegraypony @GidadoRilwan @LindaSuhler @realDonaldTrump @PeteHegseth @foxandfriends And the moon is green cheesâ€¦ https://t.co/7SVJpjc8yu\n"
     ]
    }
   ],
   "source": [
    "# Create API object to gather twitter data\n",
    "consumer_key = config.CONSUMER_KEY\n",
    "consumer_secret = config.CONSUMER_SECRET\n",
    "access_token = config.ACCESS_TOKEN\n",
    "access_secret = config.ACCESS_SECRET\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "api = tweepy.API(auth,\n",
    "                 wait_on_rate_limit = True,\n",
    "                 wait_on_rate_limit_notify = True,)\n",
    "\n",
    "\n",
    "results = api.search(q='cheese', count=100)\n",
    "\n",
    "print(results[1].text)\n",
    "\n",
    "\n",
    "# # Using the tweet IDs in the WeRateDogs Twitter archive, \n",
    "# # query the Twitter API for each tweet's JSON data\n",
    "# data = {}\n",
    "\n",
    "# tweet = api.get_status(tweet_id, tweet_mode='extended')\n",
    "# print(tweet.text)\n",
    "# data.append(tweet)\n",
    "# # except tweepy.TweepError:\n",
    "# #     print('Tweet ID no longer exists.')\n",
    "\n",
    "# # Write JSON to txt file\n",
    "# with open('tweet_json.txt', 'w') as outfile:\n",
    "#     json.dump(data, outfile, sort_keys=True)\n",
    "    \n",
    "# # Convert to a pandas dataframe for analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Assessing\n",
    "After gathering the data, I assess them visually and programmatically for quality and tidiness issues. I detect and document at least eight (8) quality issues and two (2) tidiness issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Points\n",
    "Key points to keep in mind when data wrangling for this project:\n",
    "\n",
    "- You only want original ratings (no retweets) that have images. Though there are 5000+ tweets in the dataset, not all are dog ratings and some are retweets.\n",
    "- Assessing and cleaning the entire dataset completely would require a lot of time, and is not necessary to practice and demonstrate your skills in data wrangling. Therefore, the requirements of this project are only to assess and clean at least 8 quality issues and at least 2 tidiness issues in this dataset.\n",
    "- Cleaning includes merging individual pieces of data according to the rules of tidy data.\n",
    "- The fact that the rating numerators are greater than the denominators does not need to be cleaned. This unique rating system is a big part of the popularity of WeRateDogs.\n",
    "- You do not need to gather the tweets beyond August 1st, 2017. You can, but note that you won't be able to gather the image predictions for these tweets since you don't have access to the algorithm used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "Now I will clean each of the issues I documented above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze and Visualize\n",
    "Analyze and visualize the wrangled data. I produce three (3) insights and one (1) visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
